[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
/Users/emmachen/mambaforge/envs/aqlab/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:744: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.
  rank_zero_warn(
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
